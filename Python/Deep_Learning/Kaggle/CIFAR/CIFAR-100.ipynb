{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) uint8\n",
      "(50000, 1) int32\n",
      "(10000, 32, 32, 3) uint8\n",
      "(10000, 1) int32\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "print(X_train.shape, X_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(X_test.shape, X_test.dtype)\n",
    "print(y_test.shape, y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 100)\n",
    "Y_test = np_utils.to_categorical(y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "a_train, a_test, b_train, b_test = train_test_split(X_test, Y_test, test_size=0.3, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 64)        204864    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 2,742,692\n",
      "Trainable params: 2,742,692\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0820 22:13:14.877534  4500 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size = (5,5), input_shape = (32,32,3), activation = 'relu', padding='same'))\n",
    "model.add(Conv2D(128, kernel_size = (5,5), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (5,5), activation = 'relu', padding='same'))\n",
    "model.add(Conv2D(128, kernel_size = (5,5), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0820 22:13:31.010457  4500 deprecation.py:323] From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 3229s - loss: 4.2952 - acc: 0.0456 - val_loss: 3.8065 - val_acc: 0.1191\n",
      "Epoch 2/100\n",
      " - 3228s - loss: 3.7489 - acc: 0.1252 - val_loss: 3.4076 - val_acc: 0.1937\n",
      "Epoch 3/100\n",
      " - 3226s - loss: 3.4688 - acc: 0.1755 - val_loss: 3.1660 - val_acc: 0.2340\n",
      "Epoch 4/100\n",
      " - 2929s - loss: 3.2855 - acc: 0.2064 - val_loss: 2.9977 - val_acc: 0.2676\n",
      "Epoch 5/100\n",
      " - 2140s - loss: 3.1421 - acc: 0.2337 - val_loss: 2.9240 - val_acc: 0.2848\n",
      "Epoch 6/100\n",
      " - 2139s - loss: 3.0380 - acc: 0.2535 - val_loss: 2.8043 - val_acc: 0.3092\n",
      "Epoch 7/100\n",
      " - 2145s - loss: 2.9431 - acc: 0.2727 - val_loss: 2.7658 - val_acc: 0.3126\n",
      "Epoch 8/100\n",
      " - 2141s - loss: 2.8643 - acc: 0.2856 - val_loss: 2.7110 - val_acc: 0.3267\n",
      "Epoch 9/100\n",
      " - 2141s - loss: 2.7918 - acc: 0.2999 - val_loss: 2.6941 - val_acc: 0.3345\n",
      "Epoch 10/100\n",
      " - 2160s - loss: 2.7339 - acc: 0.3102 - val_loss: 2.6607 - val_acc: 0.3330\n",
      "Epoch 11/100\n",
      " - 2141s - loss: 2.6715 - acc: 0.3209 - val_loss: 2.6228 - val_acc: 0.3433\n",
      "Epoch 12/100\n",
      " - 2149s - loss: 2.6230 - acc: 0.3307 - val_loss: 2.5879 - val_acc: 0.3549\n",
      "Epoch 13/100\n",
      " - 2142s - loss: 2.5638 - acc: 0.3409 - val_loss: 2.5717 - val_acc: 0.3574\n",
      "Epoch 14/100\n",
      " - 2143s - loss: 2.5159 - acc: 0.3516 - val_loss: 2.5500 - val_acc: 0.3586\n",
      "Epoch 15/100\n",
      " - 2144s - loss: 2.4870 - acc: 0.3556 - val_loss: 2.5394 - val_acc: 0.3651\n",
      "Epoch 16/100\n",
      " - 2142s - loss: 2.4411 - acc: 0.3670 - val_loss: 2.5421 - val_acc: 0.3605\n",
      "Epoch 17/100\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = 100, batch_size = 50, verbose=2, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
