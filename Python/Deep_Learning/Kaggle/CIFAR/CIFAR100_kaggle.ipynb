{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) uint8\n",
      "(50000, 1) int64\n",
      "(10000, 32, 32, 3) uint8\n",
      "(10000, 1) int64\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "print(X_train.shape, X_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(X_test.shape, X_test.dtype)\n",
    "print(y_test.shape, y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 100)\n",
    "Y_test = np_utils.to_categorical(y_test, 100)\n",
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## history1 model(CIFAR10의 history1 model 적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 64)        204864    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 16, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 2,742,692\n",
      "Trainable params: 2,742,692\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size = (5,5), input_shape = (32,32,3), activation = 'relu', padding='same'))\n",
    "model.add(Conv2D(128, kernel_size = (5,5), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (5,5), activation = 'relu', padding='same'))\n",
    "model.add(Conv2D(128, kernel_size = (5,5), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: 4.2735 - acc: 0.0454 - val_loss: 3.8651 - val_acc: 0.1061\n",
      "Epoch 2/100\n",
      " - 16s - loss: 3.7974 - acc: 0.1156 - val_loss: 3.4832 - val_acc: 0.1839\n",
      "Epoch 3/100\n",
      " - 16s - loss: 3.5071 - acc: 0.1687 - val_loss: 3.2180 - val_acc: 0.2311\n",
      "Epoch 4/100\n",
      " - 16s - loss: 3.3118 - acc: 0.2006 - val_loss: 3.0804 - val_acc: 0.2545\n",
      "Epoch 5/100\n",
      " - 16s - loss: 3.1635 - acc: 0.2295 - val_loss: 2.8978 - val_acc: 0.2911\n",
      "Epoch 6/100\n",
      " - 16s - loss: 3.0426 - acc: 0.2506 - val_loss: 2.8626 - val_acc: 0.3024\n",
      "Epoch 7/100\n",
      " - 16s - loss: 2.9450 - acc: 0.2690 - val_loss: 2.7611 - val_acc: 0.3124\n",
      "Epoch 8/100\n",
      " - 16s - loss: 2.8647 - acc: 0.2847 - val_loss: 2.7580 - val_acc: 0.3163\n",
      "Epoch 9/100\n",
      " - 16s - loss: 2.7844 - acc: 0.2999 - val_loss: 2.6463 - val_acc: 0.3428\n",
      "Epoch 10/100\n",
      " - 16s - loss: 2.7229 - acc: 0.3119 - val_loss: 2.6378 - val_acc: 0.3347\n",
      "Epoch 11/100\n",
      " - 16s - loss: 2.6616 - acc: 0.3231 - val_loss: 2.5788 - val_acc: 0.3504\n",
      "Epoch 12/100\n",
      " - 16s - loss: 2.5998 - acc: 0.3361 - val_loss: 2.5762 - val_acc: 0.3548\n",
      "Epoch 13/100\n",
      " - 16s - loss: 2.5454 - acc: 0.3454 - val_loss: 2.5667 - val_acc: 0.3550\n",
      "Epoch 14/100\n",
      " - 16s - loss: 2.4970 - acc: 0.3545 - val_loss: 2.5011 - val_acc: 0.3695\n",
      "Epoch 15/100\n",
      " - 16s - loss: 2.4607 - acc: 0.3608 - val_loss: 2.4966 - val_acc: 0.3692\n",
      "Epoch 16/100\n",
      " - 16s - loss: 2.3956 - acc: 0.3728 - val_loss: 2.4832 - val_acc: 0.3747\n",
      "Epoch 17/100\n",
      " - 16s - loss: 2.3612 - acc: 0.3810 - val_loss: 2.4738 - val_acc: 0.3727\n",
      "Epoch 18/100\n",
      " - 16s - loss: 2.3323 - acc: 0.3898 - val_loss: 2.5210 - val_acc: 0.3655\n",
      "Epoch 19/100\n",
      " - 16s - loss: 2.2897 - acc: 0.3938 - val_loss: 2.4571 - val_acc: 0.3839\n",
      "Epoch 20/100\n",
      " - 16s - loss: 2.2647 - acc: 0.3994 - val_loss: 2.4553 - val_acc: 0.3837\n",
      "Epoch 21/100\n",
      " - 16s - loss: 2.2293 - acc: 0.4100 - val_loss: 2.4612 - val_acc: 0.3821\n",
      "Epoch 22/100\n",
      " - 16s - loss: 2.2023 - acc: 0.4137 - val_loss: 2.4776 - val_acc: 0.3797\n",
      "Epoch 23/100\n",
      " - 16s - loss: 2.1813 - acc: 0.4187 - val_loss: 2.4282 - val_acc: 0.3869\n",
      "Epoch 24/100\n",
      " - 16s - loss: 2.1452 - acc: 0.4263 - val_loss: 2.4479 - val_acc: 0.3939\n",
      "Epoch 25/100\n",
      " - 16s - loss: 2.1304 - acc: 0.4285 - val_loss: 2.4564 - val_acc: 0.3824\n",
      "Epoch 26/100\n",
      " - 16s - loss: 2.0956 - acc: 0.4360 - val_loss: 2.4456 - val_acc: 0.3876\n",
      "Epoch 27/100\n",
      " - 16s - loss: 2.0824 - acc: 0.4402 - val_loss: 2.4395 - val_acc: 0.3907\n",
      "Epoch 28/100\n",
      " - 16s - loss: 2.0561 - acc: 0.4450 - val_loss: 2.4392 - val_acc: 0.3883\n",
      "Epoch 29/100\n",
      " - 16s - loss: 2.0276 - acc: 0.4511 - val_loss: 2.4523 - val_acc: 0.3874\n",
      "Epoch 30/100\n",
      " - 16s - loss: 2.0062 - acc: 0.4545 - val_loss: 2.4244 - val_acc: 0.3972\n",
      "Epoch 31/100\n",
      " - 16s - loss: 1.9835 - acc: 0.4607 - val_loss: 2.4318 - val_acc: 0.3958\n",
      "Epoch 32/100\n",
      " - 16s - loss: 1.9737 - acc: 0.4629 - val_loss: 2.4214 - val_acc: 0.3909\n",
      "Epoch 33/100\n",
      " - 16s - loss: 1.9514 - acc: 0.4671 - val_loss: 2.4039 - val_acc: 0.3973\n",
      "Epoch 34/100\n",
      " - 16s - loss: 1.9337 - acc: 0.4726 - val_loss: 2.4340 - val_acc: 0.3908\n",
      "Epoch 35/100\n",
      " - 16s - loss: 1.9249 - acc: 0.4751 - val_loss: 2.4377 - val_acc: 0.3955\n",
      "Epoch 36/100\n",
      " - 16s - loss: 1.9072 - acc: 0.4777 - val_loss: 2.4508 - val_acc: 0.3970\n",
      "Epoch 37/100\n",
      " - 16s - loss: 1.8856 - acc: 0.4819 - val_loss: 2.4498 - val_acc: 0.3932\n",
      "Epoch 38/100\n",
      " - 16s - loss: 1.8782 - acc: 0.4867 - val_loss: 2.4384 - val_acc: 0.3972\n",
      "Epoch 39/100\n",
      " - 16s - loss: 1.8604 - acc: 0.4887 - val_loss: 2.4642 - val_acc: 0.3898\n",
      "Epoch 40/100\n",
      " - 16s - loss: 1.8411 - acc: 0.4938 - val_loss: 2.4408 - val_acc: 0.3923\n",
      "Epoch 41/100\n",
      " - 16s - loss: 1.8270 - acc: 0.4968 - val_loss: 2.4799 - val_acc: 0.3859\n",
      "Epoch 42/100\n",
      " - 16s - loss: 1.8185 - acc: 0.5017 - val_loss: 2.4573 - val_acc: 0.3958\n",
      "Epoch 43/100\n",
      " - 16s - loss: 1.8004 - acc: 0.5035 - val_loss: 2.4668 - val_acc: 0.3962\n",
      "Epoch 44/100\n",
      " - 16s - loss: 1.7980 - acc: 0.5039 - val_loss: 2.4990 - val_acc: 0.3863\n",
      "Epoch 45/100\n",
      " - 16s - loss: 1.7864 - acc: 0.5094 - val_loss: 2.4834 - val_acc: 0.3927\n",
      "Epoch 46/100\n",
      " - 16s - loss: 1.7676 - acc: 0.5102 - val_loss: 2.5085 - val_acc: 0.3883\n",
      "Epoch 47/100\n",
      " - 16s - loss: 1.7675 - acc: 0.5128 - val_loss: 2.4580 - val_acc: 0.3956\n",
      "Epoch 48/100\n",
      " - 16s - loss: 1.7417 - acc: 0.5179 - val_loss: 2.5168 - val_acc: 0.3892\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X_train, Y_train, epochs=100, batch_size=50, validation_data = (X_test, Y_test), verbose=2, callbacks = [early_stopping_callback] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 115us/step\n",
      "\n",
      " Train_Accuacy: 0.8140\n",
      "10000/10000 [==============================] - 1s 115us/step\n",
      "\n",
      " Test_Accuacy: 0.3892\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Train_Accuacy: %.4f\" % (model.evaluate(X_train, Y_train)[1]))\n",
    "\n",
    "print(\"\\n Test_Accuacy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## history2 model(regularizers, adadelta 적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 32, 32, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 16, 16, 64)        102464    \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 16, 16, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 8, 8, 64)          102464    \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 8, 8, 64)          102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 4, 4, 64)          102464    \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 4, 4, 64)          102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               51300     \n",
      "=================================================================\n",
      "Total params: 904,996\n",
      "Trainable params: 904,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size = (5,5), input_shape = (32,32,3), activation = 'relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size = (5,5), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (5,5), activation = 'relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size = (5,5), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (5,5), activation = 'relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size = (5,5), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (5,5), activation = 'relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size = (5,5), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 4.5470 - acc: 0.0159 - val_loss: 4.2671 - val_acc: 0.0317\n",
      "Epoch 2/100\n",
      " - 15s - loss: 4.1887 - acc: 0.0445 - val_loss: 3.9784 - val_acc: 0.0694\n",
      "Epoch 3/100\n",
      " - 15s - loss: 3.9609 - acc: 0.0778 - val_loss: 3.8130 - val_acc: 0.1106\n",
      "Epoch 4/100\n",
      " - 15s - loss: 3.7786 - acc: 0.1103 - val_loss: 3.5837 - val_acc: 0.1490\n",
      "Epoch 5/100\n",
      " - 15s - loss: 3.6207 - acc: 0.1403 - val_loss: 3.3823 - val_acc: 0.1828\n",
      "Epoch 6/100\n",
      " - 15s - loss: 3.4699 - acc: 0.1666 - val_loss: 3.2911 - val_acc: 0.1977\n",
      "Epoch 7/100\n",
      " - 15s - loss: 3.3506 - acc: 0.1897 - val_loss: 3.3317 - val_acc: 0.1993\n",
      "Epoch 8/100\n",
      " - 15s - loss: 3.2538 - acc: 0.2062 - val_loss: 3.1236 - val_acc: 0.2245\n",
      "Epoch 9/100\n",
      " - 15s - loss: 3.1753 - acc: 0.2236 - val_loss: 3.0264 - val_acc: 0.2570\n",
      "Epoch 10/100\n",
      " - 15s - loss: 3.1040 - acc: 0.2369 - val_loss: 3.0153 - val_acc: 0.2555\n",
      "Epoch 11/100\n",
      " - 15s - loss: 3.0512 - acc: 0.2476 - val_loss: 2.9146 - val_acc: 0.2817\n",
      "Epoch 12/100\n",
      " - 15s - loss: 3.0021 - acc: 0.2593 - val_loss: 2.8860 - val_acc: 0.2830\n",
      "Epoch 13/100\n",
      " - 15s - loss: 2.9500 - acc: 0.2700 - val_loss: 2.8357 - val_acc: 0.2963\n",
      "Epoch 14/100\n",
      " - 15s - loss: 2.9230 - acc: 0.2752 - val_loss: 2.8214 - val_acc: 0.2954\n",
      "Epoch 15/100\n",
      " - 15s - loss: 2.8801 - acc: 0.2837 - val_loss: 2.8018 - val_acc: 0.3012\n",
      "Epoch 16/100\n",
      " - 15s - loss: 2.8670 - acc: 0.2873 - val_loss: 2.8218 - val_acc: 0.2994\n",
      "Epoch 17/100\n",
      " - 15s - loss: 2.8408 - acc: 0.2921 - val_loss: 2.7866 - val_acc: 0.3012\n",
      "Epoch 18/100\n",
      " - 15s - loss: 2.8185 - acc: 0.2967 - val_loss: 2.7326 - val_acc: 0.3198\n",
      "Epoch 19/100\n",
      " - 15s - loss: 2.7877 - acc: 0.3072 - val_loss: 2.7756 - val_acc: 0.3118\n",
      "Epoch 20/100\n",
      " - 15s - loss: 2.7819 - acc: 0.3067 - val_loss: 2.7606 - val_acc: 0.3157\n",
      "Epoch 21/100\n",
      " - 15s - loss: 2.7728 - acc: 0.3107 - val_loss: 2.7266 - val_acc: 0.3237\n",
      "Epoch 22/100\n",
      " - 15s - loss: 2.7535 - acc: 0.3127 - val_loss: 2.7251 - val_acc: 0.3191\n",
      "Epoch 23/100\n",
      " - 15s - loss: 2.7482 - acc: 0.3142 - val_loss: 2.7014 - val_acc: 0.3243\n",
      "Epoch 24/100\n",
      " - 15s - loss: 2.7428 - acc: 0.3176 - val_loss: 2.6799 - val_acc: 0.3267\n",
      "Epoch 25/100\n",
      " - 15s - loss: 2.7192 - acc: 0.3214 - val_loss: 2.6675 - val_acc: 0.3356\n",
      "Epoch 26/100\n",
      " - 15s - loss: 2.7268 - acc: 0.3218 - val_loss: 2.7289 - val_acc: 0.3238\n",
      "Epoch 27/100\n",
      " - 15s - loss: 2.7135 - acc: 0.3238 - val_loss: 2.7149 - val_acc: 0.3261\n",
      "Epoch 28/100\n",
      " - 15s - loss: 2.7141 - acc: 0.3240 - val_loss: 2.6743 - val_acc: 0.3327\n",
      "Epoch 29/100\n",
      " - 15s - loss: 2.6971 - acc: 0.3263 - val_loss: 2.7102 - val_acc: 0.3251\n",
      "Epoch 30/100\n",
      " - 15s - loss: 2.7086 - acc: 0.3251 - val_loss: 2.7734 - val_acc: 0.3207\n",
      "Epoch 31/100\n",
      " - 15s - loss: 2.6833 - acc: 0.3312 - val_loss: 2.7795 - val_acc: 0.3174\n",
      "Epoch 32/100\n",
      " - 15s - loss: 2.6790 - acc: 0.3328 - val_loss: 2.6865 - val_acc: 0.3345\n",
      "Epoch 33/100\n",
      " - 15s - loss: 2.6819 - acc: 0.3288 - val_loss: 2.7180 - val_acc: 0.3254\n",
      "Epoch 34/100\n",
      " - 15s - loss: 2.6895 - acc: 0.3312 - val_loss: 2.6790 - val_acc: 0.3333\n",
      "Epoch 35/100\n",
      " - 15s - loss: 2.6714 - acc: 0.3337 - val_loss: 2.6408 - val_acc: 0.3403\n",
      "Epoch 36/100\n",
      " - 15s - loss: 2.6691 - acc: 0.3368 - val_loss: 2.6432 - val_acc: 0.3378\n",
      "Epoch 37/100\n",
      " - 15s - loss: 2.6607 - acc: 0.3361 - val_loss: 2.7600 - val_acc: 0.3217\n",
      "Epoch 38/100\n",
      " - 15s - loss: 2.6802 - acc: 0.3354 - val_loss: 2.7175 - val_acc: 0.3294\n",
      "Epoch 39/100\n",
      " - 15s - loss: 2.6750 - acc: 0.3359 - val_loss: 2.6763 - val_acc: 0.3391\n",
      "Epoch 40/100\n",
      " - 15s - loss: 2.6719 - acc: 0.3370 - val_loss: 2.6351 - val_acc: 0.3513\n",
      "Epoch 41/100\n",
      " - 15s - loss: 2.6896 - acc: 0.3344 - val_loss: 2.7005 - val_acc: 0.3387\n",
      "Epoch 42/100\n",
      " - 15s - loss: 2.6872 - acc: 0.3343 - val_loss: 2.6759 - val_acc: 0.3372\n",
      "Epoch 43/100\n",
      " - 15s - loss: 2.6534 - acc: 0.3416 - val_loss: 2.6671 - val_acc: 0.3389\n",
      "Epoch 44/100\n",
      " - 15s - loss: 2.6719 - acc: 0.3370 - val_loss: 2.6967 - val_acc: 0.3364\n",
      "Epoch 45/100\n",
      " - 15s - loss: 2.6667 - acc: 0.3392 - val_loss: 2.7115 - val_acc: 0.3315\n",
      "Epoch 46/100\n",
      " - 15s - loss: 2.6871 - acc: 0.3364 - val_loss: 2.7153 - val_acc: 0.3350\n",
      "Epoch 47/100\n",
      " - 15s - loss: 2.6719 - acc: 0.3389 - val_loss: 2.6365 - val_acc: 0.3415\n",
      "Epoch 48/100\n",
      " - 15s - loss: 2.6806 - acc: 0.3360 - val_loss: 2.6825 - val_acc: 0.3340\n",
      "Epoch 49/100\n",
      " - 15s - loss: 2.6708 - acc: 0.3403 - val_loss: 2.6741 - val_acc: 0.3395\n",
      "Epoch 50/100\n",
      " - 15s - loss: 2.6620 - acc: 0.3402 - val_loss: 2.6810 - val_acc: 0.3428\n",
      "Epoch 51/100\n",
      " - 15s - loss: 2.6679 - acc: 0.3417 - val_loss: 2.6570 - val_acc: 0.3334\n",
      "Epoch 52/100\n",
      " - 15s - loss: 2.6790 - acc: 0.3375 - val_loss: 2.7003 - val_acc: 0.3349\n",
      "Epoch 53/100\n",
      " - 15s - loss: 2.6782 - acc: 0.3407 - val_loss: 2.7595 - val_acc: 0.3214\n",
      "Epoch 54/100\n",
      " - 15s - loss: 2.6771 - acc: 0.3389 - val_loss: 2.6410 - val_acc: 0.3492\n",
      "Epoch 55/100\n",
      " - 15s - loss: 2.6736 - acc: 0.3406 - val_loss: 2.6218 - val_acc: 0.3409\n",
      "Epoch 56/100\n",
      " - 15s - loss: 2.6693 - acc: 0.3382 - val_loss: 2.6656 - val_acc: 0.3353\n",
      "Epoch 57/100\n",
      " - 15s - loss: 2.6831 - acc: 0.3380 - val_loss: 2.6838 - val_acc: 0.3436\n",
      "Epoch 58/100\n",
      " - 15s - loss: 2.6656 - acc: 0.3422 - val_loss: 2.6698 - val_acc: 0.3462\n",
      "Epoch 59/100\n",
      " - 15s - loss: 2.6756 - acc: 0.3407 - val_loss: 2.6304 - val_acc: 0.3481\n",
      "Epoch 60/100\n",
      " - 15s - loss: 2.6713 - acc: 0.3422 - val_loss: 2.6550 - val_acc: 0.3480\n",
      "Epoch 61/100\n",
      " - 15s - loss: 2.6909 - acc: 0.3395 - val_loss: 2.8562 - val_acc: 0.3056\n",
      "Epoch 62/100\n",
      " - 15s - loss: 2.6849 - acc: 0.3409 - val_loss: 2.9637 - val_acc: 0.2877\n",
      "Epoch 63/100\n",
      " - 15s - loss: 2.6745 - acc: 0.3402 - val_loss: 2.6496 - val_acc: 0.3496\n",
      "Epoch 64/100\n",
      " - 15s - loss: 2.6789 - acc: 0.3420 - val_loss: 2.6295 - val_acc: 0.3500\n",
      "Epoch 65/100\n",
      " - 15s - loss: 2.6772 - acc: 0.3422 - val_loss: 2.6969 - val_acc: 0.3385\n",
      "Epoch 66/100\n",
      " - 15s - loss: 2.7012 - acc: 0.3386 - val_loss: 2.6550 - val_acc: 0.3392\n",
      "Epoch 67/100\n",
      " - 15s - loss: 2.6576 - acc: 0.3426 - val_loss: 2.6632 - val_acc: 0.3482\n",
      "Epoch 68/100\n",
      " - 15s - loss: 2.6854 - acc: 0.3420 - val_loss: 2.7171 - val_acc: 0.3329\n",
      "Epoch 69/100\n",
      " - 15s - loss: 2.6732 - acc: 0.3395 - val_loss: 2.6663 - val_acc: 0.3424\n",
      "Epoch 70/100\n",
      " - 15s - loss: 2.6845 - acc: 0.3397 - val_loss: 2.8469 - val_acc: 0.3125\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = 100, batch_size = 50, verbose=2, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 114us/step\n",
      "\n",
      " Train_Accuacy: 0.3858\n",
      "10000/10000 [==============================] - 1s 113us/step\n",
      "\n",
      " Test_Accuacy: 0.3126\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Train_Accuacy: %.4f\" % (model.evaluate(X_train, Y_train)[1]))\n",
    "\n",
    "print(\"\\n Test_Accuacy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론: history1의 Train_Accuacy는 0.8140, Test_Accuacy는 0.3892으로 history3(Train_Accuacy: 0.3858, Test_Accuacy: 0.3126)보다 더 높았음. 그러나 처리 속도는 엇비슷함(CIFAR100기준)\n",
    "\n",
    "#### cf) 이전 history2 모델에 Flatten 이후 Dense를 128로 주었는데, train과 test accuracy가 0.1로 고정되어 있었음. 그래서 512으로 다시 한 번 준 것이 지금의 history2 모델.-> dropout값이 0.5였기 때문에 그렇게 이상한 수치가 나온게 아닐까 싶음."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
